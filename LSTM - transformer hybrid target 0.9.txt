# LSTM - transformer hybrid target 0.9


import pandas as pd
import numpy as np
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, LayerNormalization, MultiHeadAttention, Conv1D, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt


# Load processed data
data = pd.read_csv('/content/drive/MyDrive/MINI01/merged-files/processed_data.csv')
data['datetime'] = pd.to_datetime(data['datetime'])

# Extract selected features and target (code 33 only)
selected_glucose_codes = ['48', '58', '60', '62', '64']
insulin_codes = ['33']  # Focus on code 33
target_columns = insulin_codes



# Create time features
def create_time_features(df):
    df = df.copy()
    df['hour_sin'] = np.sin(2 * np.pi * df['datetime'].dt.hour / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['datetime'].dt.hour / 24)
    df['weekday_sin'] = np.sin(2 * np.pi * df['datetime'].dt.weekday / 7)
    df['weekday_cos'] = np.cos(2 * np.pi * df['datetime'].dt.weekday / 7)
    hour = df['datetime'].dt.hour
    df['morning'] = ((hour >= 6) & (hour < 10)).astype(int)
    df['noon'] = ((hour >= 11) & (hour < 14)).astype(int)
    df['evening'] = ((hour >= 17) & (hour < 21)).astype(int)
    return df

data = create_time_features(data)

# Add glucose trend features
data = data.sort_values(['patient_id', 'datetime']).reset_index(drop=True)
def add_glucose_features(df, glucose_cols):
    df = df.copy()
    for col in glucose_cols:
        df[f'{col}_lag1'] = df.groupby('patient_id')[col].shift(1)
        df[f'{col}_lag2'] = df.groupby('patient_id')[col].shift(2)
        df[f'{col}_lag1'].fillna(0, inplace=True)
        df[f'{col}_lag2'].fillna(0, inplace=True)
        df[f'{col}_present'] = (df[col] > 0).astype(int)
        df[f'{col}_diff'] = df.groupby('patient_id')[col].diff()
        df[f'{col}_diff'].fillna(0, inplace=True)
    return df

data = add_glucose_features(df=data, glucose_cols=selected_glucose_codes)



# Add insulin history features for code 33 only
def add_insulin_features(df, insulin_cols):
    df = df.copy()
    for col in insulin_cols:
        df[f'{col}_used'] = (df[col] > 0).astype(int)
        df[f'{col}_prev'] = df.groupby('patient_id')[col].shift(1)
        df[f'{col}_prev2'] = df.groupby('patient_id')[col].shift(2)
        df[f'{col}_prev'].fillna(0, inplace=True)
        df[f'{col}_prev2'].fillna(0, inplace=True)
    return df

data = add_insulin_features(df=data, insulin_cols=insulin_codes)




# Keep original data for plotting
original_data = data[['patient_id', 'datetime']].copy()

# Define feature columns
feature_columns = (
    selected_glucose_codes + [f'{col}_lag1' for col in selected_glucose_codes] +
    [f'{col}_lag2' for col in selected_glucose_codes] + [f'{col}_diff' for col in selected_glucose_codes] +
    [f'{col}_present' for col in selected_glucose_codes] + [f'{col}_prev' for col in insulin_codes] +
    [f'{col}_prev2' for col in insulin_codes] + [f'{col}_used' for col in insulin_codes] +
    ['hour_sin', 'hour_cos', 'weekday_sin', 'weekday_cos', 'morning', 'noon', 'evening']
)
data_for_model = data[['patient_id'] + feature_columns + insulin_codes]



# Scale features and target
def scale_features(df, feature_cols, target_cols):
    df_scaled = df.copy()
    feature_scaler = RobustScaler()
    target_scaler = RobustScaler()
    df_scaled[feature_cols] = feature_scaler.fit_transform(df[feature_cols])
    df_scaled[target_cols] = target_scaler.fit_transform(df[target_cols])
    return df_scaled, feature_scaler, target_scaler

data_scaled, feature_scaler, target_scaler = scale_features(data_for_model, feature_columns, insulin_codes)



# Stratified patient split with insulin usage check
def stratified_patient_split(data, insulin_cols, test_size=0.2, random_state=42):
    patient_insulin = data.groupby('patient_id')[insulin_cols].mean().sum(axis=1)
    sorted_patients = patient_insulin.sort_values().index.tolist()
    n_patients = len(sorted_patients)
    n_test = int(n_patients * test_size)
    test_indices = list(range(0, n_patients, 5))[:n_test]
    test_patients = [sorted_patients[i] for i in test_indices]
    train_patients = [p for p in sorted_patients if p not in test_patients]
    test_patients_filtered = []
    min_non_zero_ratio = 0.1
    for pid in test_patients:
        non_zero_ratio = (data[data['patient_id'] == pid]['33'] > 0).mean()
        if non_zero_ratio >= min_non_zero_ratio:
            test_patients_filtered.append(pid)
        else:
            train_patients.append(pid)
    return train_patients, test_patients_filtered

train_patients, test_patients_filtered = stratified_patient_split(data, insulin_codes)



# Sequence creation with timestamps
def create_sequences_per_patient(data, patient_ids, seq_length, feature_indices, target_index):
    X, y, time_indices = [], [], []
    patient_index_map = {}
    count = 0
    for patient_id in patient_ids:
        patient_data = data[data['patient_id'] == patient_id].drop(columns=['patient_id']).values
        patient_times = original_data[original_data['patient_id'] == patient_id]['datetime'].values
        for i in range(len(patient_data) - seq_length):
            X.append(patient_data[i:i + seq_length, feature_indices])
            y.append(patient_data[i + seq_length, target_index])
            time_indices.append(patient_times[i + seq_length] if i + seq_length < len(patient_times) else patient_times[-1])
            count += 1
    return np.array(X), np.array(y), np.array(time_indices)




# Create sequences
SEQ_LENGTH = 4
feature_indices = [data_scaled.columns.get_loc(col) - 1 for col in feature_columns]
target_index = data_scaled.columns.get_loc('33') - 1
X_train, y_train, _ = create_sequences_per_patient(data_scaled, train_patients, SEQ_LENGTH, feature_indices, target_index)
X_test, y_test, test_times = create_sequences_per_patient(data_scaled, test_patients_filtered, SEQ_LENGTH, feature_indices, target_index)


import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, LayerNormalization, MultiHeadAttention, Conv1D, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt
import numpy as np

# Define the hybrid LSTM-Transformer model
def build_hybrid_model(input_shape, num_heads=4, ff_dim=64, dropout_rate=0.2):
    inputs = Input(shape=input_shape)  # Shape: (seq_length, num_features)

    # LSTM Branch: Captures temporal dependencies
    lstm_out = LSTM(256, return_sequences=True)(inputs)
    lstm_out = Dropout(dropout_rate)(lstm_out)
    lstm_out = LSTM(64, return_sequences=True)(lstm_out)
    lstm_out = Dropout(dropout_rate)(lstm_out)

    # Transformer Encoder Branch: Attention-based feature extraction
    attention_out = MultiHeadAttention(num_heads=num_heads, key_dim=64)(lstm_out, lstm_out)
    attention_out = Dropout(dropout_rate)(attention_out)
    attention_out = LayerNormalization(epsilon=1e-6)(attention_out + lstm_out)  # Residual connection
    ff_out = Dense(ff_dim, activation='relu')(attention_out)  # Feed-forward network
    ff_out = Dropout(dropout_rate)(ff_out)
    # Change the output dimension of the Dense layer to match the LSTM output (64)
    ff_out = Dense(64, activation='relu')(ff_out) # Match LSTM output feature dim
    transformer_out = LayerNormalization(epsilon=1e-6)(attention_out + ff_out)  # Residual connection

    # Flatten and Dense layers for final prediction
    flat_out = Flatten()(transformer_out)
    dense_out = Dense(64, activation='relu')(flat_out)
    dense_out = Dropout(dropout_rate)(dense_out)
    outputs = Dense(1)(dense_out)  # Single output for insulin code '33'

    # Build and compile model
    model = Model(inputs=inputs, outputs=outputs)
    optimizer = Adam(learning_rate=0.001)
    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])
    return model

# Model parameters
input_shape = (SEQ_LENGTH, len(feature_columns))  # (sequence length, number of features)
hybrid_model = build_hybrid_model(input_shape=input_shape, num_heads=4, ff_dim=64, dropout_rate=0.2)

# Callbacks for training
early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)

# Train the model
history = hybrid_model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=100,
    batch_size=32,
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

# Evaluate the model
y_pred_scaled = hybrid_model.predict(X_test)
y_test_unscaled = target_scaler.inverse_transform(y_test.reshape(-1, 1))
y_pred_unscaled = target_scaler.inverse_transform(y_pred_scaled)

# Calculate metrics
mae = mean_absolute_error(y_test_unscaled, y_pred_unscaled)
mse = mean_squared_error(y_test_unscaled, y_pred_unscaled)
r2 = r2_score(y_test_unscaled, y_pred_unscaled)

print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"RÂ² Score: {r2:.4f}")

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['mae'], label='Train MAE')
plt.plot(history.history['val_mae'], label='Validation MAE')
plt.title('Model MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.show()

# Plot predictions vs actuals
plt.figure(figsize=(10, 6))
plt.plot(test_times[:200], y_test_unscaled[:200], label='Actual Insulin (Code 33)', marker='o')
plt.plot(test_times[:200], y_pred_unscaled[:200], label='Predicted Insulin (Code 33)', marker='x')
plt.title('Actual vs Predicted Insulin Usage (First 100 Test Samples)')
plt.xlabel('Time')
plt.ylabel('Insulin Value')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

def plot_weekly_actual_vs_predicted(y_test, y_pred, test_times, patient_id, patient_index_map):
    """
    Plot actual vs predicted insulin usage for a patient, week by week.

    Parameters:
    - y_test: Array of actual insulin values (unscaled).
    - y_pred: Array of predicted insulin values (unscaled).
    - test_times: Array of timestamps corresponding to test predictions.
    - patient_id: ID of the patient to plot.
    - patient_index_map: Dictionary mapping patient IDs to their sequence indices in the test set.
    """
    # Get indices for the specified patient
    patient_indices = patient_index_map.get(patient_id, [])
    if not patient_indices:
        print(f"No data found for Patient {patient_id}")
        return

    # Extract patient-specific data
    patient_actual = y_test[patient_indices]
    patient_predicted = y_pred[patient_indices].flatten()  # Flatten to ensure 1D array
    patient_times = test_times[patient_indices]

    # Sort by time to ensure chronological order
    sorted_indices = np.argsort(patient_times)
    patient_times = patient_times[sorted_indices]
    patient_actual = patient_actual[sorted_indices]
    patient_predicted = patient_predicted[sorted_indices]

    # Define weekly intervals
    start_date = pd.Timestamp(patient_times.min())
    end_date = start_date + pd.Timedelta(days=7)

    # Iterate over weeks
    while start_date < patient_times.max():
        # Filter data for the current week
        mask = (patient_times >= start_date) & (patient_times < end_date)
        week_times = patient_times[mask]

        # Skip if no data for this week
        if len(week_times) == 0:
            start_date += pd.Timedelta(days=7)
            end_date += pd.Timedelta(days=7)
            continue

        week_actual = patient_actual[mask]
        week_predicted = patient_predicted[mask]

        # Create the plot
        plt.figure(figsize=(10, 6))
        plt.plot(week_times, week_actual, label='Actual Insulin (Code 33)',
                 color='blue', linestyle='-', marker='o', markersize=5)
        plt.plot(week_times, week_predicted, label='Predicted Insulin (Code 33)',
                 color='red', linestyle='--', marker='x', markersize=5)

        # Customize the plot
        plt.xlabel('Time')
        plt.ylabel('Insulin Dose (Units)')
        plt.title(f'Actual vs Predicted Insulin for Patient {patient_id} - '
                  f'{start_date.date()} to {end_date.date()}')
        plt.legend()
        plt.xticks(rotation=45)
        plt.grid(True, linestyle='--', alpha=0.7)  # Add grid for better readability
        plt.tight_layout()

        # Display the plot
        plt.show()

        # Move to the next week
        start_date += pd.Timedelta(days=7)
        end_date += pd.Timedelta(days=7)

# Example usage with your data
# Assuming test_patients_filtered, y_test_inv, y_pred_inv, test_times, and patient_index_map are defined
patient_id = test_patients_filtered[4] if len(test_patients_filtered) > 5 else test_patients_filtered[0]
plot_weekly_actual_vs_predicted(y_test_inv, y_pred_inv, test_times, patient_id, patient_index_map)


